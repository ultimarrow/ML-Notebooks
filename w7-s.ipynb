{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7d95183f",
      "metadata": {
        "id": "7d95183f"
      },
      "source": [
        "# COMP5318 Week 7: Introduction to Keras and Multilayer Perceptrons"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2361070",
      "metadata": {
        "id": "c2361070"
      },
      "source": [
        "Though an old idea, interest in Artificial Neural Networks has dramatically increased in recent times alongside an increase in available training data and computing power. Research has spawned a multitude of different network types and improvements which build on the ideas of the multilayer perceptron, and neural networks currently exhibit the best performance on many problems. The attraction is clear: neural networks are versatile and very powerful, with the ability to approximate any possible mapping of inputs to outputs given a sufficient number of neurons. \n",
        "\n",
        "However, despite their popularity, NNs are not always the most appropriate solution to every problem. They have limited interpretability (contrary to algorithms such as decision trees), are prone to overfitting due to their high complexity and number of parameters, can be difficult to design and tune hyperparameters (as we will see in today's lab), and can have very long runtimes if we utilise large networks. Like any powerful tool, their use should be carefully considered before deployment. \n",
        "\n",
        "In this lab, we will introduce you to the implementation of multilayer percepton (MLP) networks using the Keras library and explore the hyperparameters of multilayer perceptrons."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee98eeb",
      "metadata": {
        "id": "4ee98eeb"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2f33863",
      "metadata": {
        "id": "e2f33863"
      },
      "source": [
        "We begin by importing commonly used packages and setting up our plotting environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "53fbbf9f",
      "metadata": {
        "id": "53fbbf9f"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import time\n",
        "\n",
        "# Make the notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set up inline plotting and figure/axis labels\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36737db1",
      "metadata": {
        "id": "36737db1"
      },
      "source": [
        "## 2. Keras: A Simple Deep Learning API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e543737",
      "metadata": {
        "id": "7e543737"
      },
      "source": [
        "So far in the course, we have implemented various algorithms using the sklearn library. Today, we would like to introduce **Keras** as the core deep learning library we will use in the course. \n",
        "\n",
        "[Keras](https://keras.io) is very flexible and feature-rich, but in large part retains the simplicity of sklearn (and even shares some of its syntax). Technically, it is an easy-to-use frontend which typically relies on the [TensorFlow](https://www.tensorflow.org) library to handle the matrix-heavy computations underlying neural networks. TensorFlow and similar libraries such as [PyTorch](https://pytorch.org) also have the ability to run computations on GPU hardware, which can drastically decrease runtimes by exploiting their many cores for parallel calculations.\n",
        "\n",
        "Let's now handle the setup of Keras and TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc4d0d60",
      "metadata": {
        "id": "bc4d0d60"
      },
      "source": [
        "### Installing TensorFlow and Keras\n",
        "\n",
        "If tensorflow is not already installed on your system, you can utilise pip (the python package installer) to easily download and install the package. This command will also take care of the Keras installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d35c86",
      "metadata": {
        "id": "87d35c86"
      },
      "outputs": [],
      "source": [
        "# Run this cell to install tensorflow in the same python install as the kernel\n",
        "!{sys.executable} -m pip install -U tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257caf46",
      "metadata": {
        "id": "257caf46"
      },
      "source": [
        "For these tutorials, we will not require a GPU. However, in case you wish to experiment with larger neural networks and thus desire GPU support, please note that the installation process will be more involved, and you will need to install extra libraries such as CUDA. This [installation guide](https://www.tensorflow.org/install/gpu) may be a useful reference. Another option for GPU support is to utilise preconfigured cloud instances (many different providers - usually paid), or an online GPU python notebook service such as [Google Colaboratory](https://colab.research.google.com) (free and paid tiers).\n",
        "\n",
        "While we are in the process of setting things up, we will also install the [SciKeras](https://github.com/adriangb/scikeras) library, which can make our Keras models directly compatible with sklearn grid searches, ensembles, and other functionality with which we are already familiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e25637",
      "metadata": {
        "id": "56e25637"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m pip install -U scikeras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31e36c3",
      "metadata": {
        "id": "f31e36c3"
      },
      "source": [
        "With the installation handled, we can now proceed to import tensorflow and keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1d8d8143",
      "metadata": {
        "id": "1d8d8143"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Ensure stability across runs\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4539ae",
      "metadata": {
        "id": "fa4539ae"
      },
      "source": [
        "## 3. Building an MLP Image Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca2d6e2",
      "metadata": {
        "id": "1ca2d6e2"
      },
      "source": [
        "To introduce you to defining and using MLP models in the Keras library, we will build an image classifier. Image classification is a popular application of neural networks, and one in which performance often greatly exceeds that of the traditional ML models we have covered so far due to the complex mapping required from pixel inputs to classes.\n",
        "\n",
        "Let's begin by loading our dataset, inspecting it, and performing any required preprocessing. It is important to begin with this step as it will influence how we wish to design the network. For example, it will determine how we need to encode the outputs, and the difficulty of the task will roughly guide us on a reasonable initial size for the network."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc99a5c",
      "metadata": {
        "id": "1bc99a5c"
      },
      "source": [
        "### Data loading, exploration and preprocessing\n",
        "\n",
        "You may recall the MNIST dataset from the PCA task at the end of last week's tutorial.\n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digit images is frequently used by machine learning tutorials and developers who wish to prototype their models before deploying to other datasets. It is widely available and, morevoer, the task is simple and the images are low dimensional, which is important for training and testing models/ideas out quickly.\n",
        "\n",
        "Keras provides a convenience module ```keras.datasets``` ([documentation](https://keras.io/api/datasets/)) to quickly load several of these 'prototyping' datasets, including MNIST. Let's load the data now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1ee0e77d",
      "metadata": {
        "id": "1ee0e77d"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST data\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2231979a",
      "metadata": {
        "id": "2231979a"
      },
      "source": [
        "The data comes already split into a train and test set. To find the number of samples in each set, we can examine the shape of the data arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d200a1e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d200a1e9",
        "outputId": "0dd3a1e4-0c73-443d-b3d6-c0b6ac19a016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_full: (60000, 28, 28)\n",
            "Shape of y_train_full: (60000,)\n",
            "Shape of X_test: (10000, 28, 28)\n",
            "Shape of y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of X_train_full: {X_train_full.shape}\")\n",
        "print(f\"Shape of y_train_full: {y_train_full.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa115fe5",
      "metadata": {
        "id": "aa115fe5"
      },
      "source": [
        "We have a training set of 60000 examples and a test set of 10000 examples. From this output we can also deduce that the images are represented as a 28x28 grid, meaning after flattening there will be $28*28=784$ input features for our network. The MNIST images are black and white, since there is only one value per pixel (rather than 3 channels for an RGB image)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c855a3d",
      "metadata": {
        "id": "9c855a3d"
      },
      "source": [
        "Looking at the data type informs us that each pixel intensity is represented as a byte (```uint8```), which can take values from 0 to 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "90d86fd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90d86fd8",
        "outputId": "c570b383-75af-40eb-d474-14634416927e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d87b7a0",
      "metadata": {
        "id": "6d87b7a0"
      },
      "source": [
        "Without delving into too much detail, it is often a good idea to normalise or scale the input features to a 0-1 range. Most weight initialisation methods make such assumptions, and large inputs can cause gradients very close to 0 after passing the neuron output through an activation function, hindering your training process.\n",
        "\n",
        "Let's simply divide the pixel values by 255, converting them to floats in the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a9f3b65f",
      "metadata": {
        "id": "a9f3b65f"
      },
      "outputs": [],
      "source": [
        "# Scale the data to the range 0-1\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc59016",
      "metadata": {
        "id": "2fc59016"
      },
      "source": [
        "We can now visualise some images to better understand the problem our model will aim to solve.\n",
        "\n",
        "The numpy array for one example can be plotted using ```plt.imshow```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ecdcf9b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ecdcf9b3",
        "outputId": "18ecbb50-46d5-430f-fb94-7ce1abd9612c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(X_train_full[0], cmap=\"binary\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23752db8",
      "metadata": {
        "id": "23752db8"
      },
      "source": [
        "Let's visualise more examples in a grid to get a better idea of their characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "343b1dcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "343b1dcc",
        "outputId": "bca1c445-abb8-4c0a-e0ce-7c5f655f52f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x345.6 with 40 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def plot_examples(data, n_rows=4, n_cols=10):\n",
        "    \"\"\"Plot a grid of MNIST examples of a specified size.\"\"\"\n",
        "    \n",
        "    # Size figure depending on the size of the grid\n",
        "    plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "    \n",
        "    for row in range(n_rows):\n",
        "        for col in range(n_cols):\n",
        "            \n",
        "            # Get next index of image\n",
        "            index = n_cols * row + col\n",
        "            \n",
        "            # Plot the image at appropriate place in grid\n",
        "            plt.subplot(n_rows, n_cols, index + 1)\n",
        "            plt.imshow(data[index], cmap=\"binary\")\n",
        "            plt.axis('off')\n",
        "            \n",
        "    plt.show()\n",
        "\n",
        "plot_examples(X_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e582b58e",
      "metadata": {
        "id": "e582b58e"
      },
      "source": [
        "We see that the images are size-normalised and centred. The minimal preprocessing required for this dataset is part of its attraction.\n",
        "\n",
        "Finally, we need to examine the class labels as this will determine the output encoding of our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d74a5c7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d74a5c7d",
        "outputId": "ab463c8a-5eac-46eb-aff5-394fc1c6ff55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 4 1 9]\n",
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "# Check the format of the label by looking at the first five examples\n",
        "print(y_train_full[0:5])\n",
        "\n",
        "# List all unique labels in the training set\n",
        "print(np.unique(y_train_full))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ab37fe",
      "metadata": {
        "id": "a3ab37fe"
      },
      "source": [
        "As expected, we have ten labels corresponding to the different digits. The labels are provided as indices, as opposed to one hot vectors (where 3 would be represented as ```[0001000000]```)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564b6dde",
      "metadata": {
        "id": "564b6dde"
      },
      "source": [
        "### Creating a validation set\n",
        "\n",
        "When training and tuning neural networks, having a third data split called the validation set is very useful. During training we will need to determine the appropriate point to stop training to minimise overfitting, however we should not use the test set to do this, as we may bias our training process to this particular test set, and it would no longer be a fair measure of the generalisation ability of the network. Hence, we can use the validation set for this purpose. Additionally, if we wish to tune hyperparameters it is often infeasible to use k-fold cross validation due to its long runtime, so we are sometimes forced to evaluate a single training run using the validation set instead.\n",
        "\n",
        "Let's set aside 10% of the original training data for this purpose using sklearn's ```train_test_split```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a69839bd",
      "metadata": {
        "id": "a69839bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, train_size=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1825c9",
      "metadata": {
        "id": "4a1825c9"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "With our data fully prepared, it is now time to design our multilayer perceptron network. Neural network design can be difficult, with infinite possible combinations of hidden layers and numbers of neurons in each. While an MLP with one hidden layer can model any problem with enough neurons, deeper networks with multiple layers often have much higher parameter efficiency, using less weights (and hence less computation) to solve the same problem.\n",
        "\n",
        "Although there are few firm rules, with practice and exposure to neural networks in different contexts, you will develop an intuition for the appropriate starting design for your network's hidden layers depending on your problem and computational constraints. Tuning these design parameters and stopping training early to avoid overfitting can also help allevaite concern over the initial design.\n",
        "\n",
        "Today, we aim to solve a relatively simple task, and importantly, we aim to use a network which we can train and evaluate in a feasible time during today's lab. We have defined the following feedforward network below using Keras' Sequential framework ([documentation](https://keras.io/api/models/)), suitable for models where there is a single stack of layers connected sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b0cacea2",
      "metadata": {
        "id": "b0cacea2"
      },
      "outputs": [],
      "source": [
        "# Define our MLP layer by layer\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"tanh\"),\n",
        "    keras.layers.Dense(100, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c826bb6",
      "metadata": {
        "id": "1c826bb6"
      },
      "source": [
        "Note that our first layer simply flattens our input for the next layer. Here, we also define the size of the input, which will determine the number of weights between the input layer and first hidden layer. If you do not specify the input shape, Keras will simply wait until you begin to pass data to the model to actually build it.\n",
        "\n",
        "For our hidden layers, we have utilised the ReLU activation function (different activation functions are discussed below). Each of these dense layers maintains the weight (and bias) matrix for the connections between the neurons and their inputs.\n",
        "\n",
        "The final layer is determined by the nature of our classification problem. We have ten classes, so we require 10 output neurons, and we utilise the softmax function ($\\frac{e^{z_{i}}}{\\sum_{j=1}^{K} e^{z_{j}}}$) to convert the raw outputs of this layer into a probability distribution over the classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d891d7c0",
      "metadata": {
        "id": "d891d7c0"
      },
      "source": [
        "With so many connections between the neurons in each layer, we can end up with a lot of parameters. Let's take a look at our model using ```model.summary()```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "140be956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "140be956",
        "outputId": "6d2dda38-64c5-40b6-cc94-69884d20d614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879aa3a5",
      "metadata": {
        "id": "879aa3a5"
      },
      "source": [
        "We can also access the model weights directly and inspect them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "fbb5609b",
      "metadata": {
        "id": "fbb5609b"
      },
      "outputs": [],
      "source": [
        "weights, biases = model.layers[1].get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "ee0b9cce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0b9cce",
        "outputId": "50933d8b-ad11-4ec1-c155-1500f4205b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 300)\n",
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "print(weights.shape)\n",
        "print(biases.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4b778230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b778230",
        "outputId": "031d911d-310c-46b0-ca9a-b93445c0d0ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
              "         0.03859074, -0.06889391],\n",
              "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
              "        -0.02763776, -0.04165364],\n",
              "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
              "         0.07121518, -0.07331658],\n",
              "       ...,\n",
              "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
              "         0.00228987,  0.05581069],\n",
              "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
              "         0.00034875,  0.02878492],\n",
              "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
              "         0.00272203, -0.06793761]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "13a02edc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13a02edc",
        "outputId": "ed8497fe-8628-4f1c-d3b4-c893d1a2cdfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "biases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89db6122",
      "metadata": {
        "id": "89db6122"
      },
      "source": [
        "#### Discussion Question\n",
        "\n",
        "Note that the biases are initially zero, but the weights are initialised to small values. What would happen if the weights were also initialised to zero?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b825979",
      "metadata": {
        "id": "2b825979"
      },
      "source": [
        "#### Solution\n",
        "Geron explains this well in \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow : Concepts, Tools, and Techniques to Build Intelligent Systems\" (pp 291):\n",
        "\n",
        "\"If you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical. In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it wont be too smart. If instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3c9c77",
      "metadata": {
        "id": "3f3c9c77"
      },
      "source": [
        "### Specifying the optimiser and loss function\n",
        "\n",
        "Before we can use our model, we need to specify some important training parameters and 'compile' the model.\n",
        "\n",
        "Here, we will use the basic SGD learning algorithm, with a learning rate of 0.1. Our loss function depends on our problem. For a classification task such as ours, we can score the probability distribution output from the softmax layer of our model against the known labels using Cross Entropy loss. Since our labels are in index form rather than encoded as one-hot vectors, as we discussed earlier, we utilise the ```sparse_categorical_crossentropy``` loss. See [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses) for documentation on the available loss functions in Keras. It is important to ensure the loss function you are using is compatible with the format of your labels.\n",
        "\n",
        "Finally, we need to tell our model that our metric of interest is accuracy, so that this is reported during training and when we evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "53ceb7bb",
      "metadata": {
        "id": "53ceb7bb"
      },
      "outputs": [],
      "source": [
        "# Instantiate optimiser and compile the model.\n",
        "opt = keras.optimizers.SGD(learning_rate=5e-2)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b418ff",
      "metadata": {
        "id": "b4b418ff"
      },
      "source": [
        "### Training and evaluating the model\n",
        "\n",
        "Simple model training in Keras is essentially as easy as in sklearn, which is in stark contrast to many other neural network libraries.\n",
        "\n",
        "The training process may take several minutes to run depending on your hardware. As training progresses, watch carefully how the training and validation accuracy change and spot if the model begins to overfit the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "48ee676b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ee676b",
        "outputId": "ab4ba97b-b3ec-44c7-d857-f895d3c5a62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3494 - accuracy: 0.9010 - val_loss: 0.2285 - val_accuracy: 0.9312\n",
            "Epoch 2/20\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.1987 - accuracy: 0.9428 - val_loss: 0.1676 - val_accuracy: 0.9510\n",
            "Epoch 3/20\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1491 - accuracy: 0.9566 - val_loss: 0.1372 - val_accuracy: 0.9608\n",
            "Epoch 4/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1201 - accuracy: 0.9650 - val_loss: 0.1255 - val_accuracy: 0.9653\n",
            "Epoch 5/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.1060 - val_accuracy: 0.9688\n",
            "Epoch 6/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0846 - accuracy: 0.9755 - val_loss: 0.1022 - val_accuracy: 0.9695\n",
            "Epoch 7/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 0.0913 - val_accuracy: 0.9732\n",
            "Epoch 8/20\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0635 - accuracy: 0.9821 - val_loss: 0.0884 - val_accuracy: 0.9728\n",
            "Epoch 9/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.0809 - val_accuracy: 0.9757\n",
            "Epoch 10/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0489 - accuracy: 0.9864 - val_loss: 0.0766 - val_accuracy: 0.9768\n",
            "Epoch 11/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0433 - accuracy: 0.9885 - val_loss: 0.0738 - val_accuracy: 0.9767\n",
            "Epoch 12/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0382 - accuracy: 0.9903 - val_loss: 0.0728 - val_accuracy: 0.9780\n",
            "Epoch 13/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0340 - accuracy: 0.9910 - val_loss: 0.0742 - val_accuracy: 0.9772\n",
            "Epoch 14/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0302 - accuracy: 0.9932 - val_loss: 0.0680 - val_accuracy: 0.9788\n",
            "Epoch 15/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0265 - accuracy: 0.9935 - val_loss: 0.0699 - val_accuracy: 0.9797\n",
            "Epoch 16/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0233 - accuracy: 0.9949 - val_loss: 0.0684 - val_accuracy: 0.9792\n",
            "Epoch 17/20\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 0.0672 - val_accuracy: 0.9798\n",
            "Epoch 18/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 0.0641 - val_accuracy: 0.9808\n",
            "Epoch 19/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 0.0649 - val_accuracy: 0.9812\n",
            "Epoch 20/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.0658 - val_accuracy: 0.9810\n"
          ]
        }
      ],
      "source": [
        "# Train the classifier.\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e3c519",
      "metadata": {
        "id": "b1e3c519"
      },
      "source": [
        "Calling the ```fit``` method returns a dictionary of the training history, which we can utilise to visualise the change in training and validation accuracy over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "49b597f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "49b597f1",
        "outputId": "9dc67568-4acf-4618-daa1-0fbf750de321"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the history dictionary to a Pandas dataframe and extract the accuracies\n",
        "accuracies = pd.DataFrame(history.history)[['accuracy', 'val_accuracy']]\n",
        "\n",
        "# Plot the accuracies\n",
        "accuracies.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0.8, 1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b9f889",
      "metadata": {
        "id": "31b9f889"
      },
      "source": [
        "Evidently, choosing the appropriate place to stop our training is important. While this can be done manually, there are also different methods (such as [Keras callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)) to automate 'early stopping' from the validation accuracy trends."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b16b21df",
      "metadata": {
        "id": "b16b21df"
      },
      "source": [
        "To ultimately check the model's generalisation ability, we should evaluate on the test set, which had no influence in the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3b17eff7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b17eff7",
        "outputId": "fadc2e26-a315-48f6-b9df-6eaa170ccb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9795\n",
            "Accuracy on test data: 0.9795\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the classifier on the test data.\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy on test data: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e30b6a",
      "metadata": {
        "id": "d5e30b6a"
      },
      "source": [
        "We can also look directly at our model's predictions. The ```predict``` method will return the final outputs from our model - recall this was a probability distribution over the different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "9605bb97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9605bb97",
        "outputId": "205dfce6-6598-49e1-b801-1808dd27ae7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Sample several test examples\n",
        "X_test_sample = X_test[:3]\n",
        "\n",
        "# Get probability of each class from model\n",
        "y_proba = model.predict(X_test_sample).round(2)\n",
        "print(y_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7e5b7c",
      "metadata": {
        "id": "6c7e5b7c"
      },
      "source": [
        "To get the index of the class with the maximum probability (our model's class prediction), we can use the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "91766f29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91766f29",
        "outputId": "b52ce223-9cc6-41d2-99d8-53399a1960e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1]\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(y_proba, axis=-1)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34ae42cf",
      "metadata": {
        "id": "34ae42cf"
      },
      "source": [
        "Let's verify the predictions by inspecting the corresponding images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "cc0f63f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "cc0f63f9",
        "outputId": "73730a0a-7eb7-4c52-a85c-9e1c9ee16ccb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 259.2x86.4 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_examples(X_test, n_rows=1, n_cols=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8f58f8",
      "metadata": {
        "id": "1e8f58f8"
      },
      "source": [
        "## 4. Parameter Search for Neural Networks\n",
        "\n",
        "Hyperparameter tuning is especially difficult for neural networks due to two factors. \n",
        "\n",
        "Firstly, the flexibility of neural networks means there are many possible hyperparameters to tweak. In a basic MLP implementation, parameters we can possibly tune include:\n",
        "- number of hidden layers\n",
        "- number of neurons in each layer\n",
        "- activation functions\n",
        "- learning rate\n",
        "- optimiser\n",
        "- batch size \n",
        "\n",
        "The second difficulty is that the runtime of neural networks is generally much higher than traditional ML algorithms unless we run our algorithms on powerful GPUs (which can better parallelise the computations).\n",
        "\n",
        "The result is that we often have to tradeoff between an exhaustive parameter search and a long runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfae3d05",
      "metadata": {
        "id": "cfae3d05"
      },
      "source": [
        "Let's define a function which allows us to quickly build a Keras model with our desired parameters. We can use this to try out different parameter combinations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "469ccfae",
      "metadata": {
        "id": "469ccfae"
      },
      "outputs": [],
      "source": [
        "def build_mlp(\n",
        "    n_hidden_layers=2, n_hidden_neurons=50,\n",
        "    activation_function=\"relu\", input_shape=[28,28]\n",
        "):\n",
        "    \"\"\"Build a Keras MLP for 10 class classification with desired parameters.\"\"\"\n",
        "    \n",
        "    model = keras.models.Sequential()\n",
        "    \n",
        "    # Add the input layer\n",
        "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "    \n",
        "    # Add the hidden layers with desired size and activation function\n",
        "    for layer in range(n_hidden_layers):\n",
        "        model.add(keras.layers.Dense(n_hidden_neurons, activation=\"relu\"))\n",
        "        \n",
        "    # Add the output layer for 10 class classification\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26379f25",
      "metadata": {
        "id": "26379f25"
      },
      "source": [
        "### Using sklearn grid searches with Keras models\n",
        "\n",
        "We could conduct a parameter search by writing our own loop over parameter values and simply using the validation set to approximate the performance of the different combinations.\n",
        "\n",
        "However, it is also possible to use sklearn's parameter search utilities with Keras models. Previously, this functionality was included in Keras as ```keras.wrappers.scikit_learn```, however the functionality has now been taken over by SciKeras\n",
        "\n",
        "Using SciKeras, we can use a wrapper which allows our Keras classifier to act like a typical sklearn classifier. The wrapper will handle the compilation of our model, and we need to pass the parameters we wish to tune as arguments to its constructor. From there, we can set up a grid search just like we have in the previous weeks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f9ad2fc0",
      "metadata": {
        "id": "f9ad2fc0"
      },
      "outputs": [],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Create a KerasClassifier object which works with sklearn grid searches\n",
        "# We need to pass default values of arguments in build_mlp if we wish to tune them\n",
        "keras_classifier = KerasClassifier(build_mlp,\n",
        "                                   n_hidden_layers=2,\n",
        "                                   n_hidden_neurons=50,\n",
        "                                   activation_function=\"relu\",\n",
        "                                   loss=\"sparse_categorical_crossentropy\",\n",
        "                                   optimizer=\"sgd\",\n",
        "                                   optimizer__lr=0.01,\n",
        "                                   metrics=[\"accuracy\"]\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2621352",
      "metadata": {
        "id": "b2621352"
      },
      "source": [
        "For now, let's consider models with two hidden layers and tune over several other parameters.\n",
        "\n",
        "The following cell will take a long time to run (possibly several hours depending on your hardware), and it is **not recommended to run it during the lab**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "fa19f5ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa19f5ef",
        "outputId": "7cff9675-ea98-4a16-9c0f-e4b423f43e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3484 - accuracy: 0.8974\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1578 - accuracy: 0.9544\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1116 - accuracy: 0.9671\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0850 - accuracy: 0.9749\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0670 - accuracy: 0.9800\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0544 - accuracy: 0.9829\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0423 - accuracy: 0.9861\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0342 - accuracy: 0.9891\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0197 - accuracy: 0.9945\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0159 - accuracy: 0.9960\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0130 - accuracy: 0.9964\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0092 - accuracy: 0.9981\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9991\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9996\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9998\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0024 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9998\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3636 - accuracy: 0.8890\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1601 - accuracy: 0.9501\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1126 - accuracy: 0.9654\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.9736\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0685 - accuracy: 0.9779\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0547 - accuracy: 0.9825\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0435 - accuracy: 0.9868\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.9887\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0287 - accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0237 - accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0175 - accuracy: 0.9954\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0148 - accuracy: 0.9962\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0098 - accuracy: 0.9979\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0089 - accuracy: 0.9977\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9983\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 0.9987\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3656 - accuracy: 0.8914\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1618 - accuracy: 0.9508\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1118 - accuracy: 0.9660\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0878 - accuracy: 0.9732\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0675 - accuracy: 0.9788\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0547 - accuracy: 0.9829\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.9861\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0360 - accuracy: 0.9891\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0278 - accuracy: 0.9920\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9940\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0174 - accuracy: 0.9950\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0132 - accuracy: 0.9967\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9979\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0073 - accuracy: 0.9987\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9993\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9996\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0025 - accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8092 - accuracy: 0.7968\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3523 - accuracy: 0.9008\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2966 - accuracy: 0.9156\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2618 - accuracy: 0.9251\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2361 - accuracy: 0.9342\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9396\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1976 - accuracy: 0.9439\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1822 - accuracy: 0.9486\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1696 - accuracy: 0.9519\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1580 - accuracy: 0.9553\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1475 - accuracy: 0.9583\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1381 - accuracy: 0.9614\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1303 - accuracy: 0.9638\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1229 - accuracy: 0.9654\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1160 - accuracy: 0.9681\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1097 - accuracy: 0.9692\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1038 - accuracy: 0.9714\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0984 - accuracy: 0.9729\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.9744\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0896 - accuracy: 0.9751\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8908 - accuracy: 0.7729\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3564 - accuracy: 0.8988\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2924 - accuracy: 0.9161\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2560 - accuracy: 0.9258\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2297 - accuracy: 0.9339\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2094 - accuracy: 0.9395\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1923 - accuracy: 0.9445\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1794 - accuracy: 0.9491\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1676 - accuracy: 0.9521\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1575 - accuracy: 0.9546\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.9569\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1408 - accuracy: 0.9599\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1330 - accuracy: 0.9614\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1263 - accuracy: 0.9643\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1204 - accuracy: 0.9657\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1142 - accuracy: 0.9676\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1093 - accuracy: 0.9689\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1035 - accuracy: 0.9711\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0988 - accuracy: 0.9723\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0942 - accuracy: 0.9735\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8489 - accuracy: 0.7874\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3543 - accuracy: 0.8996\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2962 - accuracy: 0.9153\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2631 - accuracy: 0.9250\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2378 - accuracy: 0.9333\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2180 - accuracy: 0.9375\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2007 - accuracy: 0.9426\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1866 - accuracy: 0.9468\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1739 - accuracy: 0.9504\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1625 - accuracy: 0.9543\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1527 - accuracy: 0.9564\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1439 - accuracy: 0.9589\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1353 - accuracy: 0.9618\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1284 - accuracy: 0.9636\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1216 - accuracy: 0.9665\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1153 - accuracy: 0.9677\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.9692\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1043 - accuracy: 0.9708\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0992 - accuracy: 0.9734\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0943 - accuracy: 0.9740\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.1128 - accuracy: 0.3264\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.5844 - accuracy: 0.6811\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.0795 - accuracy: 0.7799\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7893 - accuracy: 0.8206\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6395 - accuracy: 0.8438\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5527 - accuracy: 0.8593\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4968 - accuracy: 0.8692\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4579 - accuracy: 0.8771\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4296 - accuracy: 0.8837\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8877\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3904 - accuracy: 0.8913\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3762 - accuracy: 0.8947\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3643 - accuracy: 0.8976\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3541 - accuracy: 0.9002\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3452 - accuracy: 0.9018\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3371 - accuracy: 0.9040\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3298 - accuracy: 0.9061\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3232 - accuracy: 0.9083\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3169 - accuracy: 0.9100\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3115 - accuracy: 0.9109\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0391 - accuracy: 0.4195\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4472 - accuracy: 0.7043\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9735 - accuracy: 0.7872\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7346 - accuracy: 0.8260\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6119 - accuracy: 0.8470\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5388 - accuracy: 0.8579\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4901 - accuracy: 0.8678\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4553 - accuracy: 0.8753\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4291 - accuracy: 0.8808\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4085 - accuracy: 0.8856\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3917 - accuracy: 0.8899\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3777 - accuracy: 0.8929\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3656 - accuracy: 0.8959\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3553 - accuracy: 0.8981\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3462 - accuracy: 0.9002\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3377 - accuracy: 0.9022\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3304 - accuracy: 0.9046\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3237 - accuracy: 0.9062\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3171 - accuracy: 0.9077\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3114 - accuracy: 0.9100\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 2.0342 - accuracy: 0.4151\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4012 - accuracy: 0.7018\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9326 - accuracy: 0.7933\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7125 - accuracy: 0.8296\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5994 - accuracy: 0.8504\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5310 - accuracy: 0.8635\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4848 - accuracy: 0.8732\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4512 - accuracy: 0.8810\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4260 - accuracy: 0.8859\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4062 - accuracy: 0.8901\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3903 - accuracy: 0.8935\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3771 - accuracy: 0.8960\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3659 - accuracy: 0.8983\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3562 - accuracy: 0.9002\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.9023\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3399 - accuracy: 0.9049\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3332 - accuracy: 0.9064\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3267 - accuracy: 0.9082\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3209 - accuracy: 0.9100\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3155 - accuracy: 0.9117\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3316 - accuracy: 0.9021\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1427 - accuracy: 0.9574\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0983 - accuracy: 0.9703\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.9790\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0538 - accuracy: 0.9839\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0406 - accuracy: 0.9878\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9916\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0234 - accuracy: 0.9932\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0165 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9969\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9984\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 0.9993\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9996\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9998\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.4249e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3310 - accuracy: 0.9012\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1387 - accuracy: 0.9570\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0968 - accuracy: 0.9690\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.9771\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0538 - accuracy: 0.9833\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0423 - accuracy: 0.9866\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0311 - accuracy: 0.9902\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0229 - accuracy: 0.9933\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0166 - accuracy: 0.9954\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0121 - accuracy: 0.9971\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9980\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0065 - accuracy: 0.9988\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9996\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0031 - accuracy: 0.9996\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 8.7718e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3339 - accuracy: 0.9011\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1402 - accuracy: 0.9580\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0950 - accuracy: 0.9713\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0722 - accuracy: 0.9785\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0528 - accuracy: 0.9841\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0421 - accuracy: 0.9877\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0319 - accuracy: 0.9911\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0243 - accuracy: 0.9929\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0177 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0123 - accuracy: 0.9975\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9981\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9990\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9994\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0031 - accuracy: 0.9998\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.5010e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7816 - accuracy: 0.8013\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3401 - accuracy: 0.9039\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2837 - accuracy: 0.9193\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2493 - accuracy: 0.9302\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2245 - accuracy: 0.9374\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2038 - accuracy: 0.9427\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1869 - accuracy: 0.9471\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1717 - accuracy: 0.9523\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1591 - accuracy: 0.9553\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1480 - accuracy: 0.9592\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1379 - accuracy: 0.9615\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.9647\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1212 - accuracy: 0.9664\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1140 - accuracy: 0.9682\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1075 - accuracy: 0.9704\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1012 - accuracy: 0.9726\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0956 - accuracy: 0.9740\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0900 - accuracy: 0.9758\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.9766\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0814 - accuracy: 0.9778\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7864 - accuracy: 0.8051\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3382 - accuracy: 0.9038\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2804 - accuracy: 0.9188\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2459 - accuracy: 0.9280\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2199 - accuracy: 0.9363\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1988 - accuracy: 0.9430\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1804 - accuracy: 0.9485\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1661 - accuracy: 0.9528\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1531 - accuracy: 0.9560\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1423 - accuracy: 0.9592\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1326 - accuracy: 0.9625\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1242 - accuracy: 0.9648\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1159 - accuracy: 0.9678\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1091 - accuracy: 0.9691\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1028 - accuracy: 0.9714\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0967 - accuracy: 0.9732\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0915 - accuracy: 0.9744\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0859 - accuracy: 0.9765\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0814 - accuracy: 0.9775\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0768 - accuracy: 0.9788\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7819 - accuracy: 0.8052\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3418 - accuracy: 0.9035\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2845 - accuracy: 0.9197\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2501 - accuracy: 0.9296\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2240 - accuracy: 0.9370\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2035 - accuracy: 0.9421\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1855 - accuracy: 0.9480\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1710 - accuracy: 0.9522\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1583 - accuracy: 0.9557\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1469 - accuracy: 0.9594\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1371 - accuracy: 0.9615\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1284 - accuracy: 0.9646\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1198 - accuracy: 0.9676\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1129 - accuracy: 0.9695\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1062 - accuracy: 0.9707\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0999 - accuracy: 0.9726\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0943 - accuracy: 0.9742\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0889 - accuracy: 0.9757\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.9779\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0409 - accuracy: 0.4215\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3758 - accuracy: 0.7317\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9092 - accuracy: 0.8081\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6924 - accuracy: 0.8404\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.8591\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5127 - accuracy: 0.8704\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4679 - accuracy: 0.8789\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4359 - accuracy: 0.8849\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4121 - accuracy: 0.8890\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3932 - accuracy: 0.8928\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3780 - accuracy: 0.8958\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3654 - accuracy: 0.8986\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3546 - accuracy: 0.9012\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3452 - accuracy: 0.9034\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3368 - accuracy: 0.9054\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3292 - accuracy: 0.9070\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3223 - accuracy: 0.9091\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3159 - accuracy: 0.9110\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3100 - accuracy: 0.9130\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3047 - accuracy: 0.9143\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.9832 - accuracy: 0.4482\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3005 - accuracy: 0.7281\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8678 - accuracy: 0.8089\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6684 - accuracy: 0.8437\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5633 - accuracy: 0.8624\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4992 - accuracy: 0.8741\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4562 - accuracy: 0.8815\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4254 - accuracy: 0.8869\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4022 - accuracy: 0.8908\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3840 - accuracy: 0.8949\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3692 - accuracy: 0.8982\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3568 - accuracy: 0.9005\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3461 - accuracy: 0.9029\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3371 - accuracy: 0.9054\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3290 - accuracy: 0.9070\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3216 - accuracy: 0.9091\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3151 - accuracy: 0.9095\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3091 - accuracy: 0.9116\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3033 - accuracy: 0.9130\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2982 - accuracy: 0.9146\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 2.0534 - accuracy: 0.4223\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4194 - accuracy: 0.7178\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9442 - accuracy: 0.7943\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7084 - accuracy: 0.8315\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5872 - accuracy: 0.8543\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5151 - accuracy: 0.8675\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4673 - accuracy: 0.8787\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4330 - accuracy: 0.8853\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4075 - accuracy: 0.8913\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3874 - accuracy: 0.8951\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3713 - accuracy: 0.8989\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3579 - accuracy: 0.9017\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3465 - accuracy: 0.9051\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3366 - accuracy: 0.9072\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3279 - accuracy: 0.9094\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3199 - accuracy: 0.9114\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3131 - accuracy: 0.9129\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3065 - accuracy: 0.9146\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3007 - accuracy: 0.9159\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2952 - accuracy: 0.9179\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=relu, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3527 - accuracy: 0.8961\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1571 - accuracy: 0.9530\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1107 - accuracy: 0.9679\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0668 - accuracy: 0.9802\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0544 - accuracy: 0.9835\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0436 - accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0347 - accuracy: 0.9890\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0280 - accuracy: 0.9914\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0234 - accuracy: 0.9928\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9948\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0142 - accuracy: 0.9964\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9981\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9990\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0044 - accuracy: 0.9995\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0030 - accuracy: 0.9998\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9998\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9999\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3522 - accuracy: 0.8923\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1518 - accuracy: 0.9529\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1078 - accuracy: 0.9669\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.9742\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0660 - accuracy: 0.9786\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0525 - accuracy: 0.9829\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0406 - accuracy: 0.9875\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0336 - accuracy: 0.9897\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0266 - accuracy: 0.9918\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9937\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0166 - accuracy: 0.9953\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0130 - accuracy: 0.9967\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9977\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9988\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9992\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3555 - accuracy: 0.8944\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1633 - accuracy: 0.9509\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1141 - accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0892 - accuracy: 0.9731\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0685 - accuracy: 0.9795\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0556 - accuracy: 0.9824\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0433 - accuracy: 0.9874\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0361 - accuracy: 0.9889\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9909\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0214 - accuracy: 0.9942\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0174 - accuracy: 0.9949\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0143 - accuracy: 0.9964\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0117 - accuracy: 0.9972\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0078 - accuracy: 0.9983\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9994\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9995\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8601 - accuracy: 0.7714\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3608 - accuracy: 0.8974\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3024 - accuracy: 0.9126\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2670 - accuracy: 0.9240\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2406 - accuracy: 0.9313\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2188 - accuracy: 0.9369\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2009 - accuracy: 0.9420\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1847 - accuracy: 0.9468\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1712 - accuracy: 0.9517\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1593 - accuracy: 0.9543\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1485 - accuracy: 0.9574\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1391 - accuracy: 0.9606\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1310 - accuracy: 0.9633\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1232 - accuracy: 0.9650\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.9677\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1101 - accuracy: 0.9691\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1041 - accuracy: 0.9715\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0984 - accuracy: 0.9736\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0937 - accuracy: 0.9744\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0897 - accuracy: 0.9762\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8616 - accuracy: 0.7754\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3557 - accuracy: 0.8982\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2982 - accuracy: 0.9131\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2650 - accuracy: 0.9235\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2404 - accuracy: 0.9308\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2198 - accuracy: 0.9358\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2017 - accuracy: 0.9419\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1875 - accuracy: 0.9465\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.9501\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1629 - accuracy: 0.9527\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1530 - accuracy: 0.9568\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1443 - accuracy: 0.9580\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1357 - accuracy: 0.9604\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1285 - accuracy: 0.9629\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1220 - accuracy: 0.9645\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1158 - accuracy: 0.9660\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1103 - accuracy: 0.9682\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1043 - accuracy: 0.9697\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0993 - accuracy: 0.9711\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0945 - accuracy: 0.9729\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8657 - accuracy: 0.7750\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3461 - accuracy: 0.9017\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2899 - accuracy: 0.9169\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2578 - accuracy: 0.9258\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2334 - accuracy: 0.9337\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2137 - accuracy: 0.9385\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1964 - accuracy: 0.9437\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1823 - accuracy: 0.9481\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1698 - accuracy: 0.9522\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1585 - accuracy: 0.9550\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1486 - accuracy: 0.9574\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1400 - accuracy: 0.9595\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1319 - accuracy: 0.9630\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1253 - accuracy: 0.9647\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1188 - accuracy: 0.9664\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1126 - accuracy: 0.9679\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.9699\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1020 - accuracy: 0.9712\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0971 - accuracy: 0.9725\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0923 - accuracy: 0.9740\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 2.0099 - accuracy: 0.4032\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3736 - accuracy: 0.7079\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9227 - accuracy: 0.7876\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7059 - accuracy: 0.8284\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5924 - accuracy: 0.8507\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5243 - accuracy: 0.8630\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4794 - accuracy: 0.8728\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4472 - accuracy: 0.8792\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4233 - accuracy: 0.8842\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4042 - accuracy: 0.8882\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3889 - accuracy: 0.8917\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8950\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3652 - accuracy: 0.8970\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3558 - accuracy: 0.8994\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.9018\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3398 - accuracy: 0.9036\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3330 - accuracy: 0.9056\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3266 - accuracy: 0.9075\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3207 - accuracy: 0.9089\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3156 - accuracy: 0.9109\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 2.0758 - accuracy: 0.3677\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4909 - accuracy: 0.6592\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.0228 - accuracy: 0.7552\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7813 - accuracy: 0.8020\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6486 - accuracy: 0.8338\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5660 - accuracy: 0.8534\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5105 - accuracy: 0.8664\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.8745\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.8810\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4189 - accuracy: 0.8858\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4008 - accuracy: 0.8903\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3856 - accuracy: 0.8941\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3728 - accuracy: 0.8966\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3618 - accuracy: 0.8992\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3523 - accuracy: 0.9007\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3435 - accuracy: 0.9031\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3359 - accuracy: 0.9053\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3288 - accuracy: 0.9073\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3221 - accuracy: 0.9088\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3163 - accuracy: 0.9101\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.1247 - accuracy: 0.3677\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.5686 - accuracy: 0.6856\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.0522 - accuracy: 0.7747\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7717 - accuracy: 0.8243\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6289 - accuracy: 0.8486\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5474 - accuracy: 0.8632\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4957 - accuracy: 0.8723\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4597 - accuracy: 0.8790\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4333 - accuracy: 0.8838\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4129 - accuracy: 0.8882\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3966 - accuracy: 0.8918\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3831 - accuracy: 0.8949\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8973\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8994\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.9015\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3453 - accuracy: 0.9027\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3384 - accuracy: 0.9041\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3318 - accuracy: 0.9062\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3258 - accuracy: 0.9074\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3202 - accuracy: 0.9087\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3277 - accuracy: 0.9041\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1429 - accuracy: 0.9584\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0987 - accuracy: 0.9708\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.9798\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0541 - accuracy: 0.9841\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0414 - accuracy: 0.9873\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0317 - accuracy: 0.9906\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0231 - accuracy: 0.9939\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9957\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0132 - accuracy: 0.9967\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0090 - accuracy: 0.9984\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0054 - accuracy: 0.9994\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9997\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9998\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0022 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.2773e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3313 - accuracy: 0.9003\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1361 - accuracy: 0.9587\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0955 - accuracy: 0.9704\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.9784\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0517 - accuracy: 0.9841\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0409 - accuracy: 0.9873\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0287 - accuracy: 0.9920\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0234 - accuracy: 0.9936\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0170 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0117 - accuracy: 0.9973\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0079 - accuracy: 0.9986\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0058 - accuracy: 0.9990\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9999\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.0618e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3364 - accuracy: 0.8997\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1427 - accuracy: 0.9578\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0970 - accuracy: 0.9708\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0743 - accuracy: 0.9775\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0538 - accuracy: 0.9840\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0421 - accuracy: 0.9879\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9903\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0244 - accuracy: 0.9934\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0167 - accuracy: 0.9959\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9970\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0092 - accuracy: 0.9983\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9988\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0046 - accuracy: 0.9995\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0030 - accuracy: 0.9997\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.5404e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7833 - accuracy: 0.8028\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3446 - accuracy: 0.9033\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2879 - accuracy: 0.9186\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2525 - accuracy: 0.9289\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2269 - accuracy: 0.9359\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2057 - accuracy: 0.9418\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1883 - accuracy: 0.9462\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1726 - accuracy: 0.9514\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1597 - accuracy: 0.9554\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1481 - accuracy: 0.9585\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1378 - accuracy: 0.9614\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1288 - accuracy: 0.9643\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.9658\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1135 - accuracy: 0.9686\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1068 - accuracy: 0.9710\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1006 - accuracy: 0.9719\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0948 - accuracy: 0.9743\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0893 - accuracy: 0.9763\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0845 - accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.9782\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7862 - accuracy: 0.7973\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3341 - accuracy: 0.9043\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2792 - accuracy: 0.9193\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2455 - accuracy: 0.9291\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2202 - accuracy: 0.9374\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2000 - accuracy: 0.9430\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1824 - accuracy: 0.9476\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1685 - accuracy: 0.9516\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1557 - accuracy: 0.9557\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1449 - accuracy: 0.9574\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1352 - accuracy: 0.9611\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1268 - accuracy: 0.9633\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1181 - accuracy: 0.9659\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1112 - accuracy: 0.9683\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1050 - accuracy: 0.9702\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0984 - accuracy: 0.9721\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0933 - accuracy: 0.9729\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.9747\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9762\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.9774\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7972 - accuracy: 0.7994\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3381 - accuracy: 0.9043\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2804 - accuracy: 0.9205\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2461 - accuracy: 0.9302\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2198 - accuracy: 0.9377\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1995 - accuracy: 0.9424\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1820 - accuracy: 0.9480\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1678 - accuracy: 0.9523\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1553 - accuracy: 0.9554\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1441 - accuracy: 0.9589\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1343 - accuracy: 0.9617\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1257 - accuracy: 0.9641\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1173 - accuracy: 0.9675\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1106 - accuracy: 0.9692\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1038 - accuracy: 0.9706\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0978 - accuracy: 0.9726\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0920 - accuracy: 0.9746\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9762\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.9773\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.9789\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0700 - accuracy: 0.3901\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4530 - accuracy: 0.7161\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9509 - accuracy: 0.7981\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7063 - accuracy: 0.8351\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5855 - accuracy: 0.8538\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5152 - accuracy: 0.8662\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4692 - accuracy: 0.8752\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4364 - accuracy: 0.8817\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4118 - accuracy: 0.8878\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3921 - accuracy: 0.8922\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3762 - accuracy: 0.8964\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3628 - accuracy: 0.9001\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3514 - accuracy: 0.9025\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.9051\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3326 - accuracy: 0.9076\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3246 - accuracy: 0.9094\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3174 - accuracy: 0.9113\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3107 - accuracy: 0.9133\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3044 - accuracy: 0.9146\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2990 - accuracy: 0.9164\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0139 - accuracy: 0.4107\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3448 - accuracy: 0.7252\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8892 - accuracy: 0.8079\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6754 - accuracy: 0.8407\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5660 - accuracy: 0.8597\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5007 - accuracy: 0.8712\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4575 - accuracy: 0.8794\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4267 - accuracy: 0.8849\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4035 - accuracy: 0.8895\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3853 - accuracy: 0.8939\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3705 - accuracy: 0.8970\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3580 - accuracy: 0.8999\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3471 - accuracy: 0.9022\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3379 - accuracy: 0.9042\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3296 - accuracy: 0.9061\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3219 - accuracy: 0.9083\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3152 - accuracy: 0.9102\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3089 - accuracy: 0.9118\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3029 - accuracy: 0.9135\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2977 - accuracy: 0.9149\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 1.9977 - accuracy: 0.4423\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3232 - accuracy: 0.7560\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8754 - accuracy: 0.8229\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6668 - accuracy: 0.8513\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5598 - accuracy: 0.8666\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4957 - accuracy: 0.8771\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4530 - accuracy: 0.8847\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4220 - accuracy: 0.8904\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3987 - accuracy: 0.8954\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3800 - accuracy: 0.8984\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3650 - accuracy: 0.9023\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3523 - accuracy: 0.9050\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.9073\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3320 - accuracy: 0.9095\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3235 - accuracy: 0.9113\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3159 - accuracy: 0.9138\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3091 - accuracy: 0.9152\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3027 - accuracy: 0.9164\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2969 - accuracy: 0.9179\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2914 - accuracy: 0.9193\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=sigmoid, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3512 - accuracy: 0.8954\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1537 - accuracy: 0.9544\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1085 - accuracy: 0.9683\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.9765\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0646 - accuracy: 0.9802\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0516 - accuracy: 0.9840\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0413 - accuracy: 0.9879\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0338 - accuracy: 0.9896\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0207 - accuracy: 0.9946\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0166 - accuracy: 0.9956\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0126 - accuracy: 0.9967\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9977\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9989\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9994\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 0.9998\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0022 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3536 - accuracy: 0.8934\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1556 - accuracy: 0.9528\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1108 - accuracy: 0.9649\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0864 - accuracy: 0.9734\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0676 - accuracy: 0.9790\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0561 - accuracy: 0.9818\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0449 - accuracy: 0.9859\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.9890\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0282 - accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0236 - accuracy: 0.9924\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0190 - accuracy: 0.9944\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0149 - accuracy: 0.9960\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0093 - accuracy: 0.9979\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9988\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0063 - accuracy: 0.9991\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9996\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0016 - accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3617 - accuracy: 0.8921\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1566 - accuracy: 0.9523\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1114 - accuracy: 0.9664\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0882 - accuracy: 0.9737\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0673 - accuracy: 0.9795\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9828\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0458 - accuracy: 0.9858\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9895\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0299 - accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0231 - accuracy: 0.9933\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0174 - accuracy: 0.9954\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0161 - accuracy: 0.9955\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0114 - accuracy: 0.9973\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0092 - accuracy: 0.9979\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9991\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9996\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8407 - accuracy: 0.7860\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3567 - accuracy: 0.8998\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3010 - accuracy: 0.9145\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2674 - accuracy: 0.9242\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2429 - accuracy: 0.9323\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2219 - accuracy: 0.9373\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2044 - accuracy: 0.9425\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1887 - accuracy: 0.9473\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1761 - accuracy: 0.9509\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1641 - accuracy: 0.9541\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1536 - accuracy: 0.9569\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1441 - accuracy: 0.9599\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1356 - accuracy: 0.9617\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1279 - accuracy: 0.9640\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.9663\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1144 - accuracy: 0.9682\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.9703\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1023 - accuracy: 0.9716\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0974 - accuracy: 0.9728\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0933 - accuracy: 0.9737\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7941 - accuracy: 0.7992\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3435 - accuracy: 0.9020\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2883 - accuracy: 0.9164\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2550 - accuracy: 0.9264\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2296 - accuracy: 0.9347\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2093 - accuracy: 0.9392\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1912 - accuracy: 0.9449\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9490\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1644 - accuracy: 0.9530\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9556\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1441 - accuracy: 0.9588\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1357 - accuracy: 0.9614\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1271 - accuracy: 0.9628\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1206 - accuracy: 0.9657\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1145 - accuracy: 0.9671\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.9684\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1035 - accuracy: 0.9706\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0977 - accuracy: 0.9716\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0931 - accuracy: 0.9734\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0887 - accuracy: 0.9746\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8660 - accuracy: 0.7663\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8969\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3044 - accuracy: 0.9139\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.2702 - accuracy: 0.9234\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2445 - accuracy: 0.9302\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2241 - accuracy: 0.9356\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2061 - accuracy: 0.9404\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1915 - accuracy: 0.9453\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1784 - accuracy: 0.9489\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1664 - accuracy: 0.9531\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1563 - accuracy: 0.9556\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1471 - accuracy: 0.9580\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1380 - accuracy: 0.9611\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1309 - accuracy: 0.9635\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1239 - accuracy: 0.9654\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1174 - accuracy: 0.9670\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1112 - accuracy: 0.9691\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1055 - accuracy: 0.9708\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1006 - accuracy: 0.9723\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0958 - accuracy: 0.9734\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.1536 - accuracy: 0.3133\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 1.6612 - accuracy: 0.6090\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 1.1511 - accuracy: 0.7270\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8537 - accuracy: 0.7877\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6926 - accuracy: 0.8269\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5947 - accuracy: 0.8487\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5305 - accuracy: 0.8631\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4856 - accuracy: 0.8732\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4531 - accuracy: 0.8792\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4281 - accuracy: 0.8845\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4086 - accuracy: 0.8890\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3927 - accuracy: 0.8920\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3795 - accuracy: 0.8955\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3682 - accuracy: 0.8973\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8992\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3495 - accuracy: 0.9019\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3416 - accuracy: 0.9037\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3343 - accuracy: 0.9053\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3277 - accuracy: 0.9071\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3217 - accuracy: 0.9084\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0351 - accuracy: 0.3598\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4311 - accuracy: 0.7038\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9461 - accuracy: 0.7988\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7090 - accuracy: 0.8331\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5908 - accuracy: 0.8511\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5211 - accuracy: 0.8645\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4749 - accuracy: 0.8731\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.8807\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4169 - accuracy: 0.8859\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3973 - accuracy: 0.8894\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3813 - accuracy: 0.8928\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3680 - accuracy: 0.8963\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3565 - accuracy: 0.8990\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3467 - accuracy: 0.9012\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3381 - accuracy: 0.9036\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3300 - accuracy: 0.9055\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3230 - accuracy: 0.9064\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3165 - accuracy: 0.9085\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3103 - accuracy: 0.9101\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3049 - accuracy: 0.9109\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0657 - accuracy: 0.3432\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4962 - accuracy: 0.6765\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.0052 - accuracy: 0.7897\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7398 - accuracy: 0.8313\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6072 - accuracy: 0.8520\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5321 - accuracy: 0.8631\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4841 - accuracy: 0.8728\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4504 - accuracy: 0.8794\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4254 - accuracy: 0.8857\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4057 - accuracy: 0.8898\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3898 - accuracy: 0.8936\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3766 - accuracy: 0.8954\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3654 - accuracy: 0.8987\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3558 - accuracy: 0.9006\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.9030\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3398 - accuracy: 0.9049\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3332 - accuracy: 0.9059\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3268 - accuracy: 0.9083\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3212 - accuracy: 0.9090\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3161 - accuracy: 0.9103\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=100, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3359 - accuracy: 0.9003\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1410 - accuracy: 0.9579\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0975 - accuracy: 0.9706\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0717 - accuracy: 0.9783\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0545 - accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0408 - accuracy: 0.9876\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0303 - accuracy: 0.9910\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0238 - accuracy: 0.9926\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0167 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0118 - accuracy: 0.9974\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9983\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0069 - accuracy: 0.9985\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9997\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0031 - accuracy: 0.9997\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0016 - accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 9.1202e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3335 - accuracy: 0.9004\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1392 - accuracy: 0.9570\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0951 - accuracy: 0.9704\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0702 - accuracy: 0.9782\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0528 - accuracy: 0.9830\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0397 - accuracy: 0.9872\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0296 - accuracy: 0.9908\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0223 - accuracy: 0.9939\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0167 - accuracy: 0.9953\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0113 - accuracy: 0.9976\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0083 - accuracy: 0.9983\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 0.9991\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0024 - accuracy: 0.9999\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.5723e-04 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 8.7416e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3278 - accuracy: 0.9024\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1420 - accuracy: 0.9574\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0965 - accuracy: 0.9706\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0729 - accuracy: 0.9785\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0527 - accuracy: 0.9841\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0412 - accuracy: 0.9880\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0314 - accuracy: 0.9911\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9942\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9973\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9984\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0061 - accuracy: 0.9990\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0044 - accuracy: 0.9996\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 0.9999\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 9.9272e-04 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 9.1685e-04 - accuracy: 1.0000\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.1; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7877 - accuracy: 0.7991\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3439 - accuracy: 0.9030\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2876 - accuracy: 0.9172\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2523 - accuracy: 0.9282\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2262 - accuracy: 0.9365\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2048 - accuracy: 0.9419\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1872 - accuracy: 0.9464\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1716 - accuracy: 0.9514\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9554\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1474 - accuracy: 0.9586\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1371 - accuracy: 0.9611\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1281 - accuracy: 0.9639\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1201 - accuracy: 0.9660\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9688\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1062 - accuracy: 0.9712\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1000 - accuracy: 0.9725\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0942 - accuracy: 0.9743\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0884 - accuracy: 0.9763\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0840 - accuracy: 0.9769\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9787\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.7820 - accuracy: 0.7987\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3429 - accuracy: 0.9023\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2879 - accuracy: 0.9169\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2541 - accuracy: 0.9267\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2282 - accuracy: 0.9349\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2072 - accuracy: 0.9405\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1887 - accuracy: 0.9445\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1744 - accuracy: 0.9491\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1612 - accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1497 - accuracy: 0.9564\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1397 - accuracy: 0.9593\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1308 - accuracy: 0.9622\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1219 - accuracy: 0.9647\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1148 - accuracy: 0.9668\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1079 - accuracy: 0.9693\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1015 - accuracy: 0.9711\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0962 - accuracy: 0.9726\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0902 - accuracy: 0.9743\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0854 - accuracy: 0.9756\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0809 - accuracy: 0.9769\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8276 - accuracy: 0.7922\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3417 - accuracy: 0.9033\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2832 - accuracy: 0.9194\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2487 - accuracy: 0.9298\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.2228 - accuracy: 0.9384\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9425\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1849 - accuracy: 0.9484\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1709 - accuracy: 0.9525\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1582 - accuracy: 0.9559\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1467 - accuracy: 0.9598\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9621\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1285 - accuracy: 0.9643\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1197 - accuracy: 0.9673\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.1126 - accuracy: 0.9696\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.1060 - accuracy: 0.9707\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0997 - accuracy: 0.9725\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0937 - accuracy: 0.9749\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0886 - accuracy: 0.9767\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.9781\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.9787\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.01; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0701 - accuracy: 0.4096\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4446 - accuracy: 0.7071\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.9473 - accuracy: 0.7908\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.7097 - accuracy: 0.8306\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5906 - accuracy: 0.8522\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5202 - accuracy: 0.8650\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4738 - accuracy: 0.8752\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4405 - accuracy: 0.8828\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4156 - accuracy: 0.8874\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3957 - accuracy: 0.8911\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3798 - accuracy: 0.8946\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3664 - accuracy: 0.8980\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3550 - accuracy: 0.9006\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3450 - accuracy: 0.9031\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3363 - accuracy: 0.9047\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3283 - accuracy: 0.9069\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3212 - accuracy: 0.9089\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3145 - accuracy: 0.9104\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3084 - accuracy: 0.9120\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3029 - accuracy: 0.9136\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0390 - accuracy: 0.4159\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.3681 - accuracy: 0.7495\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.8938 - accuracy: 0.8122\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.6783 - accuracy: 0.8394\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5705 - accuracy: 0.8556\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5061 - accuracy: 0.8686\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4630 - accuracy: 0.8772\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4321 - accuracy: 0.8831\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4086 - accuracy: 0.8874\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3900 - accuracy: 0.8914\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3750 - accuracy: 0.8950\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3623 - accuracy: 0.8981\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3512 - accuracy: 0.9007\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3419 - accuracy: 0.9031\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3335 - accuracy: 0.9057\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3257 - accuracy: 0.9073\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3190 - accuracy: 0.9089\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3127 - accuracy: 0.9102\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3067 - accuracy: 0.9127\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3014 - accuracy: 0.9137\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 2.0666 - accuracy: 0.3705\n",
            "Epoch 2/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 1.4346 - accuracy: 0.7269\n",
            "Epoch 3/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.9402 - accuracy: 0.8096\n",
            "Epoch 4/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.6996 - accuracy: 0.8416\n",
            "Epoch 5/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5802 - accuracy: 0.8596\n",
            "Epoch 6/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.5107 - accuracy: 0.8702\n",
            "Epoch 7/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4653 - accuracy: 0.8795\n",
            "Epoch 8/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4331 - accuracy: 0.8848\n",
            "Epoch 9/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.4091 - accuracy: 0.8896\n",
            "Epoch 10/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3902 - accuracy: 0.8928\n",
            "Epoch 11/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3750 - accuracy: 0.8964\n",
            "Epoch 12/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3623 - accuracy: 0.8991\n",
            "Epoch 13/20\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.3516 - accuracy: 0.9014\n",
            "Epoch 14/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3422 - accuracy: 0.9047\n",
            "Epoch 15/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3339 - accuracy: 0.9068\n",
            "Epoch 16/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3264 - accuracy: 0.9085\n",
            "Epoch 17/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3197 - accuracy: 0.9101\n",
            "Epoch 18/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3134 - accuracy: 0.9121\n",
            "Epoch 19/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3078 - accuracy: 0.9134\n",
            "Epoch 20/20\n",
            "1125/1125 [==============================] - 3s 3ms/step - loss: 0.3025 - accuracy: 0.9147\n",
            "563/563 [==============================] - 1s 2ms/step\n",
            "[CV] END activation_function=tanh, n_hidden_neurons=200, optimizer__lr=0.001; total time= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2802 - accuracy: 0.9169\n",
            "Epoch 2/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1169 - accuracy: 0.9646\n",
            "Epoch 3/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0793 - accuracy: 0.9754\n",
            "Epoch 4/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0590 - accuracy: 0.9814\n",
            "Epoch 5/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0444 - accuracy: 0.9862\n",
            "Epoch 6/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0346 - accuracy: 0.9892\n",
            "Epoch 7/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0255 - accuracy: 0.9922\n",
            "Epoch 8/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0196 - accuracy: 0.9943\n",
            "Epoch 9/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0138 - accuracy: 0.9963\n",
            "Epoch 10/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0103 - accuracy: 0.9976\n",
            "Epoch 11/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0076 - accuracy: 0.9982\n",
            "Epoch 12/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9991\n",
            "Epoch 13/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "Epoch 14/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9997\n",
            "Epoch 15/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0016 - accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 8.3643e-04 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 7.5387e-04 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 6.5531e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=KerasClassifier(activation_function='relu', loss='sparse_categorical_crossentropy', metrics=['accuracy'], model=<function build_mlp at 0x7f7de24aaef0>, n_hidden_layers=2, n_hidden_neurons=50, optimizer='sgd', optimizer__lr=0.01),\n",
              "             param_grid={'activation_function': ['relu', 'sigmoid', 'tanh'],\n",
              "                         'n_hidden_neurons': [100, 200],\n",
              "                         'optimizer__lr': [0.1, 0.01, 0.001]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "\"\"\"This cell has a long runtime. Not recommended during lab.\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"n_hidden_neurons\": [100, 200],\n",
        "    \"optimizer__lr\": [0.1, 0.01, 0.001],\n",
        "    \"activation_function\": [\"relu\", \"sigmoid\", \"tanh\"]\n",
        "}\n",
        "\n",
        "grid_search_cv = GridSearchCV(keras_classifier, param_grid, cv=3, verbose=2)\n",
        "grid_search_cv.fit(X_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "016f0a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "016f0a3d",
        "outputId": "8fa5f636-072f-4d29-e6f7-c8f0946f12b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation_function': 'sigmoid', 'n_hidden_neurons': 200, 'optimizer__lr': 0.1}\n"
          ]
        }
      ],
      "source": [
        "print(grid_search_cv.best_params_)\n",
        "best_model = grid_search_cv.best_estimator_.model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346c7dbe",
      "metadata": {
        "id": "346c7dbe"
      },
      "source": [
        "For even larger models than the MLPs we have considered here, exhaustive grid search and cross validation quickly become infeasible. Other than using more powerful hardware, one approach is to run a broad initial search using the validation set, and then narrow the search space once appropriate starting parameters are identified. There also exist many algorithsm to more efficiently search the hyperparameter space such as Bayesian Search. Ultimately, however, there is no escpaing neural network's need for computation power and their long runtimes. This is one reason why neural networks are not always the most appropriate solution to your problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61c87df",
      "metadata": {
        "id": "c61c87df"
      },
      "source": [
        "## 5. Task - Using an MLP for Regression\n",
        "\n",
        "Today we have demonstrated how to create an image classifier MLP. Beyond multi-class classification problems, MLPs can also be used to solve other types of problems, such as regression and binary classification.\n",
        "\n",
        "To create an MLP for one of these different problems, you will need to change the output encoding.\n",
        "\n",
        "For example, a binary classifier should have 1 output neuron and use a logistic output layer activation (values close to 0 represent class 0, values close to 1 represent class 1).\n",
        "\n",
        "For a regression problem, there should be one output neuron per prediction required. No output activation is necessarily required, but ReLU may be used if the output must be positive, and sigmoid/tanh can be used for bounded outputs. The other change for regression problems is the loss function (cross entropy is not appropriate for regression). Mean squared error (MSE) ([Keras documentation](https://keras.io/api/losses/)) is often used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4404a9",
      "metadata": {
        "id": "af4404a9"
      },
      "source": [
        "Below we have loaded and preprocessed the Boston Housing dataset, which contains 13 numerical attibutes of houses of Boston suburbs in the late 1970s. The target variable is the house price in thousands of dollars. For more details on the actual attributes, you can view this [link](http://lib.stat.cmu.edu/datasets/boston)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "e481c28a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e481c28a",
        "outputId": "18ca8e63-deae-495a-d2f8-e9b5fcb149b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the Boston Housing data\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.boston_housing.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "74261d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74261d07",
        "outputId": "200ddd04-8b56-42c1-c4cf-9df70142d3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_full: (404, 13)\n",
            "Shape of y_train_full: (404,)\n",
            "Shape of X_test: (102, 13)\n",
            "Shape of y_test: (102,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of X_train_full: {X_train_full.shape}\")\n",
        "print(f\"Shape of y_train_full: {y_train_full.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "a957098e",
      "metadata": {
        "id": "a957098e"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "f64c8b29",
      "metadata": {
        "id": "f64c8b29"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a validation set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# Standardise the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8e628d",
      "metadata": {
        "id": "2f8e628d"
      },
      "source": [
        "### Task\n",
        "Define, train and evaluate a regression MLP on this dataset. To achieve this, you will need to:\n",
        "- Remember to adjust the input shape and output layer appropriately for this dataset\n",
        "- Compile the model with an appropriate loss function\n",
        "- Interpret the evaluation, since for this regression problem accuracy is not a valid metric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ff31b1",
      "metadata": {
        "id": "b6ff31b1"
      },
      "source": [
        "### Solution:\n",
        "\n",
        "This is one possible simple solution using the same hidden layer structure as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "dd0991c9",
      "metadata": {
        "id": "dd0991c9"
      },
      "outputs": [],
      "source": [
        "# Define our Keras model with appropriate input size and output\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model with MSE loss\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "876bc46e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "876bc46e",
        "outputId": "d2ca024a-3507-462d-f178-49a64fd67a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 1s 22ms/step - loss: 547.7675 - val_loss: 330.2329\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 211.8402 - val_loss: 63.3655\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 49.4029 - val_loss: 32.2598\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 31.1562 - val_loss: 25.3474\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.2875 - val_loss: 20.0847\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 22.2691 - val_loss: 17.7285\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.0409 - val_loss: 15.9388\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 18.2024 - val_loss: 14.6661\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.1464 - val_loss: 13.4113\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.0479 - val_loss: 12.6765\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.2514 - val_loss: 11.9131\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.6534 - val_loss: 11.6748\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.7723 - val_loss: 10.6946\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.1478 - val_loss: 10.3933\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.8889 - val_loss: 10.0510\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.9329 - val_loss: 10.9085\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.8309 - val_loss: 9.6554\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.1047 - val_loss: 10.4408\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.1498 - val_loss: 9.3134\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.5452 - val_loss: 11.1688\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "caf6c20b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caf6c20b",
        "outputId": "e699464e-1673-4204-8c45-272765ecafce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 23.4793\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using MSE as a metric\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "a5aaabff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5aaabff",
        "outputId": "c717f5d3-32cb-45d8-fd77-2d712254874e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model prediction: 9.95; True value: 7.2\n",
            "Model prediction: 17.18; True value: 18.8\n",
            "Model prediction: 21.42; True value: 19.0\n"
          ]
        }
      ],
      "source": [
        "# Examine several model predictions\n",
        "y_pred = model.predict(X_test[:3])\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"Model prediction: {y_pred[i][0]:.2f}; True value: {y_test[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d08bbda",
      "metadata": {
        "id": "0d08bbda"
      },
      "source": [
        "## 6. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58584ac",
      "metadata": {
        "id": "b58584ac"
      },
      "source": [
        "Today, we have only scratched the surface of Keras' functionality. It is a rich library with lots of possible customisation, and a 'Functional API' ([documentation](https://keras.io/guides/functional_api/)) to create more complex models. Nevertheless, hopefully this provides a springboard for your further study and utilisation of deep learning libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f70b98",
      "metadata": {
        "id": "f2f70b98"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"tanh\"),\n",
        "    keras.layers.Dense(100, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=5e-2)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy on test data: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a582db77",
      "metadata": {
        "id": "a582db77"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "This tutorial is based on:\n",
        "\n",
        "Aurelien Geron (2019). Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow, O'Reilly."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "w7-new-solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1bc99a5c",
        "564b6dde",
        "4a1825c9",
        "89db6122",
        "2b825979",
        "3f3c9c77",
        "2f8e628d"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}